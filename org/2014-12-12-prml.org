#+TITLE: Pattern Recognition and Machine Learning
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="/css/worg.css" />
#+OPTIONS: ^:{} H:3
#+STARTUP: indent
#+CATEGORY: note


* Kernel Methods
** 对偶表示
许多线性参数模型可以转换为等价的对偶表示，在预测时也依赖于在训练数据上使用核函数后的线性组合。
在此考虑以下回归模型，其参数由正规化的最小平方损失函数决定(page293)。
$$J(\mathbf{w}) = \frac{1}{2}\sum_{n=1}^{N} {\{{\mathbf{w}}^{T} \phi ({\mathbf{x}}_{n}) - t_n\}}^{2} + \frac{\lambda}{2}{\mathbf{w}}^{T}\mathbf{w}$$
[[/img/prml/6-7.png][关于a的对偶形式]]
[[/img/prml/6-8.png][关于a的解]]
[[/img/prml/6-9.png][使用核函数和K预测]
可以将其完全转换为对偶形式，预测时也使用对偶形式。对偶形式有一下有点:
+ 完全使用核函数形式表示
+ 无需显示声明基函数
+ 预测形式中$\mathbf{w}$消去了
** 核函数
** Radial Basis Function
